{"cells": [{"cell_type": "code", "execution_count": 93, "metadata": {"collapsed": true}, "outputs": [], "source": ["SANDBOX_NAME = # Sandbox Name\n", "DATA_PATH = \"/data/sandboxes/\"+SANDBOX_NAME+\"/data/\"\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "# Spark ML Selecci\u00f3n de Variables\n", "\n", "Cargamos un dataset con informaci\u00f3n sobre partos. Este dataset tiene como variable objetivo el fallecimiento o supervivencia de los reci\u00e9n nacidos."]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "### Crear SparkSession"]}, {"cell_type": "code", "execution_count": 94, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.sql import SparkSession\n", "\n", "spark = SparkSession.builder.getOrCreate()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "### Cargar datos y comprobar schema"]}, {"cell_type": "code", "execution_count": 95, "metadata": {"collapsed": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["root\n", " |-- INFANT_ALIVE_AT_REPORT: string (nullable = true)\n", " |-- BIRTH_YEAR: integer (nullable = true)\n", " |-- BIRTH_MONTH: integer (nullable = true)\n", " |-- BIRTH_PLACE: integer (nullable = true)\n", " |-- MOTHER_AGE_YEARS: integer (nullable = true)\n", " |-- MOTHER_RACE_6CODE: integer (nullable = true)\n", " |-- MOTHER_EDUCATION: integer (nullable = true)\n", " |-- FATHER_COMBINED_AGE: integer (nullable = true)\n", " |-- FATHER_EDUCATION: integer (nullable = true)\n", " |-- MONTH_PRECARE_RECODE: integer (nullable = true)\n", " |-- CIG_BEFORE: integer (nullable = true)\n", " |-- CIG_1_TRI: integer (nullable = true)\n", " |-- CIG_2_TRI: integer (nullable = true)\n", " |-- CIG_3_TRI: integer (nullable = true)\n", " |-- MOTHER_HEIGHT_IN: integer (nullable = true)\n", " |-- MOTHER_BMI_RECODE: integer (nullable = true)\n", " |-- MOTHER_PRE_WEIGHT: integer (nullable = true)\n", " |-- MOTHER_DELIVERY_WEIGHT: integer (nullable = true)\n", " |-- MOTHER_WEIGHT_GAIN: integer (nullable = true)\n", " |-- DIABETES_PRE: string (nullable = true)\n", " |-- DIABETES_GEST: string (nullable = true)\n", " |-- HYP_TENS_PRE: string (nullable = true)\n", " |-- HYP_TENS_GEST: string (nullable = true)\n", " |-- PREV_BIRTH_PRETERM: string (nullable = true)\n", " |-- NO_RISK: integer (nullable = true)\n", " |-- NO_INFECTIONS_REPORTED: integer (nullable = true)\n", " |-- LABOR_IND: string (nullable = true)\n", " |-- LABOR_AUGM: string (nullable = true)\n", " |-- STEROIDS: string (nullable = true)\n", " |-- ANTIBIOTICS: string (nullable = true)\n", " |-- ANESTHESIA: string (nullable = true)\n", " |-- DELIV_METHOD_RECODE_COMB: integer (nullable = true)\n", " |-- ATTENDANT_BIRTH: integer (nullable = true)\n", " |-- APGAR_5: integer (nullable = true)\n", " |-- APGAR_5_RECODE: integer (nullable = true)\n", " |-- APGAR_10: integer (nullable = true)\n", " |-- APGAR_10_RECODE: integer (nullable = true)\n", " |-- INFANT_SEX: string (nullable = true)\n", " |-- OBSTETRIC_GESTATION_WEEKS: integer (nullable = true)\n", " |-- INFANT_WEIGHT_GRAMS: integer (nullable = true)\n", " |-- INFANT_ASSIST_VENTI: string (nullable = true)\n", " |-- INFANT_ASSIST_VENTI_6HRS: string (nullable = true)\n", " |-- INFANT_NICU_ADMISSION: string (nullable = true)\n", " |-- INFANT_SURFACANT: string (nullable = true)\n", " |-- INFANT_ANTIBIOTICS: string (nullable = true)\n", " |-- INFANT_SEIZURES: string (nullable = true)\n", " |-- INFANT_NO_ABNORMALITIES: integer (nullable = true)\n", " |-- INFANT_ANCEPHALY: string (nullable = true)\n", " |-- INFANT_MENINGOMYELOCELE: string (nullable = true)\n", " |-- INFANT_LIMB_REDUCTION: string (nullable = true)\n", " |-- INFANT_DOWN_SYNDROME: string (nullable = true)\n", " |-- INFANT_SUSPECTED_CHROMOSOMAL_DISORDER: string (nullable = true)\n", " |-- INFANT_NO_CONGENITAL_ANOMALIES_CHECKED: integer (nullable = true)\n", " |-- INFANT_BREASTFED: string (nullable = true)\n", "\n"]}], "source": ["# Respuesta\n", "\n", "births = spark.read.csv(DATA_PATH+'births_train.csv',sep=',', header=True, inferSchema=True) # You may try with: births.csv\n", "\n", "births.printSchema()"]}, {"cell_type": "code", "execution_count": 96, "metadata": {"collapsed": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["+----------------------+----------+-----------+-----------+----------------+-----------------+----------------+-------------------+----------------+--------------------+----------+---------+---------+---------+----------------+-----------------+-----------------+----------------------+------------------+------------+-------------+------------+-------------+------------------+-------+----------------------+---------+----------+--------+-----------+----------+------------------------+---------------+-------+--------------+--------+---------------+----------+-------------------------+-------------------+-------------------+------------------------+---------------------+----------------+------------------+---------------+-----------------------+----------------+-----------------------+---------------------+--------------------+-------------------------------------+--------------------------------------+----------------+\n", "|INFANT_ALIVE_AT_REPORT|BIRTH_YEAR|BIRTH_MONTH|BIRTH_PLACE|MOTHER_AGE_YEARS|MOTHER_RACE_6CODE|MOTHER_EDUCATION|FATHER_COMBINED_AGE|FATHER_EDUCATION|MONTH_PRECARE_RECODE|CIG_BEFORE|CIG_1_TRI|CIG_2_TRI|CIG_3_TRI|MOTHER_HEIGHT_IN|MOTHER_BMI_RECODE|MOTHER_PRE_WEIGHT|MOTHER_DELIVERY_WEIGHT|MOTHER_WEIGHT_GAIN|DIABETES_PRE|DIABETES_GEST|HYP_TENS_PRE|HYP_TENS_GEST|PREV_BIRTH_PRETERM|NO_RISK|NO_INFECTIONS_REPORTED|LABOR_IND|LABOR_AUGM|STEROIDS|ANTIBIOTICS|ANESTHESIA|DELIV_METHOD_RECODE_COMB|ATTENDANT_BIRTH|APGAR_5|APGAR_5_RECODE|APGAR_10|APGAR_10_RECODE|INFANT_SEX|OBSTETRIC_GESTATION_WEEKS|INFANT_WEIGHT_GRAMS|INFANT_ASSIST_VENTI|INFANT_ASSIST_VENTI_6HRS|INFANT_NICU_ADMISSION|INFANT_SURFACANT|INFANT_ANTIBIOTICS|INFANT_SEIZURES|INFANT_NO_ABNORMALITIES|INFANT_ANCEPHALY|INFANT_MENINGOMYELOCELE|INFANT_LIMB_REDUCTION|INFANT_DOWN_SYNDROME|INFANT_SUSPECTED_CHROMOSOMAL_DISORDER|INFANT_NO_CONGENITAL_ANOMALIES_CHECKED|INFANT_BREASTFED|\n", "+----------------------+----------+-----------+-----------+----------------+-----------------+----------------+-------------------+----------------+--------------------+----------+---------+---------+---------+----------------+-----------------+-----------------+----------------------+------------------+------------+-------------+------------+-------------+------------------+-------+----------------------+---------+----------+--------+-----------+----------+------------------------+---------------+-------+--------------+--------+---------------+----------+-------------------------+-------------------+-------------------+------------------------+---------------------+----------------+------------------+---------------+-----------------------+----------------+-----------------------+---------------------+--------------------+-------------------------------------+--------------------------------------+----------------+\n", "|                     N|      2015|          2|          1|              29|                3|               9|                 99|               9|                   4|        99|       99|       99|       99|              99|                9|              999|                   999|                99|           N|            N|           N|            N|                 N|      1|                     1|        N|         N|       N|          Y|         N|                       2|              1|      4|             2|       3|              1|         F|                       35|               2770|                  N|                       N|                    Y|               N|                 N|              N|                      0|               N|                      N|                    N|                   N|                                    N|                                     0|               N|\n", "+----------------------+----------+-----------+-----------+----------------+-----------------+----------------+-------------------+----------------+--------------------+----------+---------+---------+---------+----------------+-----------------+-----------------+----------------------+------------------+------------+-------------+------------+-------------+------------------+-------+----------------------+---------+----------+--------+-----------+----------+------------------------+---------------+-------+--------------+--------+---------------+----------+-------------------------+-------------------+-------------------+------------------------+---------------------+----------------+------------------+---------------+-----------------------+----------------+-----------------------+---------------------+--------------------+-------------------------------------+--------------------------------------+----------------+\n", "only showing top 1 row\n", "\n"]}], "source": ["# Respuesta\n", "\n", "births.show(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": [" \n", "\n", "Se puede ver la variable objetivo (_target_) \"INFANT_ALIVE_AT_REPORT\" es de tipo \"string\".  Para realizar los siguientes an\u00e1lisis la misma debe ser convertida a tipo num\u00e9rico."]}, {"cell_type": "code", "execution_count": 97, "metadata": {"collapsed": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["+----------------------+-----+\n", "|INFANT_ALIVE_AT_REPORT|count|\n", "+----------------------+-----+\n", "|                   1.0|23349|\n", "|                   0.0|22080|\n", "+----------------------+-----+\n", "\n"]}], "source": ["# Respuesta\n", "\n", "from pyspark.sql import functions as F\n", "from pyspark.sql.types import FloatType\n", "\n", "births= births.withColumn(\"INFANT_ALIVE_AT_REPORT\", F.udf(lambda x: 1.0 if x == \"Y\" else 0.0, FloatType())(\"INFANT_ALIVE_AT_REPORT\") )\n", "\n", "births.groupby(\"INFANT_ALIVE_AT_REPORT\").count().show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Todas las variables de tipo 'string' son categ\u00f3ricas. Hagamos un StringIndexer con ellas"]}, {"cell_type": "code", "execution_count": 98, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.feature import StringIndexer\n", "\n", "stringindexer_dictionary ={}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Es una buena idea guardar todos los modelos para poder acceder a los cambios para cada categor\u00eda"]}, {"cell_type": "code", "execution_count": 99, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "for element in births.dtypes:\n", "    if element[1] == 'string':\n", "        stringindexer = StringIndexer(inputCol = element[0], outputCol=element[0]+'_indexed')\n", "        stringindexer_model = stringindexer.fit(births)\n", "        births = stringindexer_model.transform(births)\n", "        births = births.drop(element[0])\n", "        \n", "        stringindexer_dictionary[element[0]] = stringindexer_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "### ChiSquared\n", "\n", "Este m\u00e9todo de selecci\u00f3n de variables se aplica a variables categ\u00f3ricas."]}, {"cell_type": "code", "execution_count": 100, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.feature import ChiSqSelector, VectorAssembler"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "El primer paso es crear un VectorAssembler de las variables categ\u00f3ricas"]}, {"cell_type": "code", "execution_count": 101, "metadata": {"collapsed": false}, "outputs": [], "source": ["# Respuesta\n", "\n", "input_cols = [element for element in births.columns if '_indexed' in element]\n", "\n", "vectorassembler = VectorAssembler(inputCols=input_cols, outputCol='categorical_assembled')\n", "births = vectorassembler.transform(births)\n", "\n", "chisquared = ChiSqSelector(featuresCol=vectorassembler.getOutputCol(), labelCol=\"INFANT_ALIVE_AT_REPORT\", numTopFeatures=5)\n", "chisquared_model = chisquared.fit(births)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Ver resultado:"]}, {"cell_type": "code", "execution_count": 102, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["[0, 1, 2, 3, 4]"]}, "execution_count": 102, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "chisquared_model.selectedFeatures"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Ver nombre de las variables:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Nota: el orden viene dado por el orden en que se han introducido las variables en el VectorAssembler."]}, {"cell_type": "code", "execution_count": 105, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["['DIABETES_PRE_indexed',\n", " 'DIABETES_GEST_indexed',\n", " 'HYP_TENS_PRE_indexed',\n", " 'HYP_TENS_GEST_indexed',\n", " 'PREV_BIRTH_PRETERM_indexed']"]}, "execution_count": 105, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "top_5_categorical = [input_cols[index] for index in chisquared_model.selectedFeatures]\n", "top_5_categorical"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "### RandomForest\n", "\n", "Este m\u00e9todo toma tanto variables categ\u00f3ricas como num\u00e9ricas. Tiene el incoveniente que es aleatorio (_random_) y los resultados pueden verse modificados. Vamos a ver como contrarrestar este problema. Adem\u00e1s, retorna importancia de las variables."]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Importamos RandomForestClassifier puesto que se trata de un problema de clasificaci\u00f3n"]}, {"cell_type": "code", "execution_count": 37, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.classification import RandomForestClassifier"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Debemos volver a crear un VectorAssembler y ejecutamos el algoritmo RandomForestClassifier."]}, {"cell_type": "code", "execution_count": 38, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "features_for_rf = [element for element in births.columns if element != 'INFANT_ALIVE_AT_REPORT' and element !='categorical_assembled']"]}, {"cell_type": "code", "execution_count": 39, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "vectorassembler = VectorAssembler(inputCols=features_for_rf, outputCol='assembled_rf')\n", "births = vectorassembler.transform(births)\n", "\n", "rf = RandomForestClassifier(featuresCol=vectorassembler.getOutputCol(), labelCol='INFANT_ALIVE_AT_REPORT')\n", "\n", "rf_model = rf.fit(births)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "De nuevo, el \u00edndice del vector viene dado por el orden de entrada de las variables en el VectorAssembler"]}, {"cell_type": "code", "execution_count": 40, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["SparseVector(53, {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0001, 4: 0.0, 5: 0.0002, 6: 0.0001, 7: 0.005, 8: 0.0038, 9: 0.0001, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0017, 15: 0.0001, 16: 0.0, 17: 0.0097, 18: 0.0, 19: 0.0, 20: 0.0017, 21: 0.0011, 22: 0.2194, 23: 0.1516, 24: 0.1991, 25: 0.0527, 26: 0.1355, 27: 0.1296, 28: 0.0182, 29: 0.0057, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0001, 34: 0.0, 35: 0.0, 36: 0.0005, 37: 0.0, 39: 0.001, 40: 0.0, 41: 0.0027, 42: 0.0052, 43: 0.0102, 44: 0.0022, 45: 0.0002, 46: 0.0, 47: 0.0003, 49: 0.0, 50: 0.0, 51: 0.0002, 52: 0.0417})"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "rf_model.featureImportances"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "* Ordenamos importancias para quedarnos con las variables que explican el x% de importancia respecto la variable objetivo. Tomaremos el 95% de importancia"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Primero, creamos una lista y almacenamos el \u00edndice para poder recuperar el nombre de la variable m\u00e1s adelante\n"]}, {"cell_type": "code", "execution_count": 41, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "importances = [(index, value) for index, value in enumerate(rf_model.featureImportances.toArray().tolist())]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Ordenamos de mayor a menor importancia"]}, {"cell_type": "code", "execution_count": 42, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "importances = sorted(importances, key=lambda value: value[1], reverse=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Nos quedamos con aquellas que explican el 95% de las variables"]}, {"cell_type": "code", "execution_count": 43, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "compt = 0\n", "important_features =[]\n", "for element in importances:\n", "    if compt < 0.95:\n", "        compt += element[1]\n", "        important_features.append((features_for_rf[element[0]], element[1]))"]}, {"cell_type": "code", "execution_count": 44, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["[('APGAR_5', 0.21941245244780555),\n", " ('APGAR_10', 0.1990509570431592),\n", " ('APGAR_5_RECODE', 0.15159174784368368),\n", " ('OBSTETRIC_GESTATION_WEEKS', 0.13550571587277377),\n", " ('INFANT_WEIGHT_GRAMS', 0.1296323667129227),\n", " ('APGAR_10_RECODE', 0.05274068115563527),\n", " ('INFANT_BREASTFED_indexed', 0.04174235857620831),\n", " ('INFANT_NO_ABNORMALITIES', 0.018203302052444317),\n", " ('INFANT_NICU_ADMISSION_indexed', 0.010209149067515246)]"]}, "execution_count": 44, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "important_features"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Ahora, veamos como evitar la aleatoriedad del RandomForest haciendo varias iteraciones y qued\u00e1ndonos con las variables que aparecen en todas las iteraciones"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Creemos una semilla (_seed_), al inicializarlo ser\u00e1 replicable."]}, {"cell_type": "code", "execution_count": 106, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "random_seed = 4\n", "num_iter = 10\n", "\n", "import random"]}, {"cell_type": "code", "execution_count": 107, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "random.seed(random_seed)\n", "\n", "random_seeds=[]\n", "\n", "while len(set(random_seeds)) < num_iter:\n", "    random_seeds.append(random.randint(0,10000))\n", "\n", "features_random_seed = []\n", "for random_seed in random_seeds:\n", "    rf = RandomForestClassifier(featuresCol=vectorassembler.getOutputCol(), labelCol='INFANT_ALIVE_AT_REPORT', seed = random_seed )\n", "    rf_model = rf.fit(births)\n", "    \n", "    importances = [(index, value) for index, value in enumerate(rf_model.featureImportances.toArray().tolist())]\n", "\n", "    #order from highest to lowest importance\n", "    importances = sorted(importances, key=lambda value: value[1], reverse=True)\n", "\n", "    #select those that explain 95% of the target variable\n", "\n", "    compt = 0\n", "    important_features =[]\n", "    for element in importances:\n", "        if compt < 0.95:\n", "            compt += element[1]\n", "            important_features.append((features_for_rf[element[0]], element[1]))\n", "    features_random_seed.append(important_features)\n"]}, {"cell_type": "code", "execution_count": 47, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["[[('OBSTETRIC_GESTATION_WEEKS', 0.1897563919934772),\n", "  ('APGAR_5_RECODE', 0.1816585782356116),\n", "  ('APGAR_10', 0.14205212924330746),\n", "  ('APGAR_5', 0.1178229597974382),\n", "  ('INFANT_BREASTFED_indexed', 0.11678964589503937),\n", "  ('APGAR_10_RECODE', 0.09949067380070632),\n", "  ('INFANT_WEIGHT_GRAMS', 0.06964752921996402),\n", "  ('MOTHER_WEIGHT_GAIN', 0.03395813029859042)],\n", " [('OBSTETRIC_GESTATION_WEEKS', 0.22373268121473489),\n", "  ('APGAR_10', 0.17550243605514046),\n", "  ('APGAR_5', 0.1459829268718799),\n", "  ('APGAR_5_RECODE', 0.1413768840867261),\n", "  ('INFANT_BREASTFED_indexed', 0.12133793312942176),\n", "  ('INFANT_WEIGHT_GRAMS', 0.07169498002361721),\n", "  ('APGAR_10_RECODE', 0.046964044119101676),\n", "  ('INFANT_ASSIST_VENTI_indexed', 0.011928566811532561),\n", "  ('INFANT_NICU_ADMISSION_indexed', 0.010463668851627677),\n", "  ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', 0.009733998844637624)],\n", " [('APGAR_5_RECODE', 0.2538788456669687),\n", "  ('APGAR_5', 0.18205609995085512),\n", "  ('OBSTETRIC_GESTATION_WEEKS', 0.14363221561476974),\n", "  ('APGAR_10_RECODE', 0.10777493046273494),\n", "  ('INFANT_WEIGHT_GRAMS', 0.10675908459085755),\n", "  ('APGAR_10', 0.10122916651136404),\n", "  ('INFANT_BREASTFED_indexed', 0.0634116014545674)],\n", " [('APGAR_5', 0.3239621923590098),\n", "  ('INFANT_WEIGHT_GRAMS', 0.16043365886757774),\n", "  ('OBSTETRIC_GESTATION_WEEKS', 0.14602376167374806),\n", "  ('APGAR_10', 0.1157864411940894),\n", "  ('APGAR_5_RECODE', 0.09587040749390902),\n", "  ('INFANT_BREASTFED_indexed', 0.06598118473046899),\n", "  ('APGAR_10_RECODE', 0.022859603432529282),\n", "  ('MOTHER_WEIGHT_GAIN', 0.01650815690377266),\n", "  ('INFANT_ASSIST_VENTI_indexed', 0.013276708778018348)],\n", " [('APGAR_5_RECODE', 0.24804028540957831),\n", "  ('APGAR_5', 0.1833431626644193),\n", "  ('APGAR_10_RECODE', 0.16781941336777711),\n", "  ('OBSTETRIC_GESTATION_WEEKS', 0.12745810756510978),\n", "  ('APGAR_10', 0.1082757903838683),\n", "  ('INFANT_BREASTFED_indexed', 0.05460829344255515),\n", "  ('INFANT_WEIGHT_GRAMS', 0.03801385364227849),\n", "  ('INFANT_NO_ABNORMALITIES', 0.012969046165945023),\n", "  ('MOTHER_WEIGHT_GAIN', 0.011493766304744874)],\n", " [('APGAR_5_RECODE', 0.3030143623153826),\n", "  ('INFANT_WEIGHT_GRAMS', 0.19339982800857788),\n", "  ('APGAR_10', 0.16216863854499822),\n", "  ('OBSTETRIC_GESTATION_WEEKS', 0.13668127048992004),\n", "  ('APGAR_5', 0.06248360189876743),\n", "  ('APGAR_10_RECODE', 0.038167051001483744),\n", "  ('INFANT_BREASTFED_indexed', 0.03382658396479116),\n", "  ('MOTHER_WEIGHT_GAIN', 0.017374861369758434),\n", "  ('INFANT_NO_ABNORMALITIES', 0.01503474564303777)],\n", " [('OBSTETRIC_GESTATION_WEEKS', 0.237779400038102),\n", "  ('APGAR_5_RECODE', 0.18950934647640869),\n", "  ('APGAR_10', 0.1460065088252552),\n", "  ('APGAR_5', 0.11636112159614145),\n", "  ('APGAR_10_RECODE', 0.10556665987750516),\n", "  ('INFANT_BREASTFED_indexed', 0.0946396822201985),\n", "  ('INFANT_WEIGHT_GRAMS', 0.03688806134889032),\n", "  ('MOTHER_WEIGHT_GAIN', 0.016605708406225685),\n", "  ('INFANT_NICU_ADMISSION_indexed', 0.013015352266160513)],\n", " [('APGAR_10_RECODE', 0.182415638243681),\n", "  ('OBSTETRIC_GESTATION_WEEKS', 0.17185071672491492),\n", "  ('APGAR_5', 0.16628098379086959),\n", "  ('APGAR_10', 0.14075939407979318),\n", "  ('APGAR_5_RECODE', 0.1289078114832749),\n", "  ('INFANT_BREASTFED_indexed', 0.0854212965217274),\n", "  ('INFANT_WEIGHT_GRAMS', 0.0739997984474869),\n", "  ('INFANT_NICU_ADMISSION_indexed', 0.010164994601770078)],\n", " [('APGAR_5', 0.3279996305016524),\n", "  ('OBSTETRIC_GESTATION_WEEKS', 0.1568330941492381),\n", "  ('APGAR_5_RECODE', 0.14744147466564958),\n", "  ('INFANT_WEIGHT_GRAMS', 0.09608600825012134),\n", "  ('APGAR_10_RECODE', 0.08778130264524037),\n", "  ('APGAR_10', 0.06477352662212048),\n", "  ('INFANT_BREASTFED_indexed', 0.06064562015066789),\n", "  ('INFANT_NO_ABNORMALITIES', 0.01569192632878858)],\n", " [('OBSTETRIC_GESTATION_WEEKS', 0.1965093734726255),\n", "  ('INFANT_WEIGHT_GRAMS', 0.18319337506294056),\n", "  ('APGAR_5', 0.1775339269752779),\n", "  ('APGAR_10', 0.15114908758524112),\n", "  ('APGAR_5_RECODE', 0.13679597233197582),\n", "  ('INFANT_BREASTFED_indexed', 0.07126575881853749),\n", "  ('INFANT_ASSIST_VENTI_indexed', 0.016279050031991704),\n", "  ('INFANT_NO_ABNORMALITIES', 0.009888928681505102),\n", "  ('MONTH_PRECARE_RECODE', 0.009122321761116204)]]"]}, "execution_count": 47, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "features_random_seed"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Tras construir esta lista de listas con informaci\u00f3n de cada iteraci\u00f3n, nos quedamos con aquellas variables que aparecen en cada iteraci\u00f3n. Veamos c\u00f3mo se hace."]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Primero convertimos la lista de listas en una sola lista"]}, {"cell_type": "code", "execution_count": 48, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["['OBSTETRIC_GESTATION_WEEKS',\n", " 'APGAR_10',\n", " 'APGAR_5_RECODE',\n", " 'APGAR_5',\n", " 'INFANT_WEIGHT_GRAMS',\n", " 'INFANT_BREASTFED_indexed']"]}, "execution_count": 48, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "flat_features = [feature for one_seed in features_random_seed for feature in one_seed]\n", "features = [element[0] for element in flat_features]\n", "\n", "from collections import Counter\n", "\n", "features_all_seeds = [element[0] for element in Counter(features).items() if element[1] == num_iter]\n", "features_all_seeds"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "\n", "Si quisi\u00e9ramos el valor de la importancia en s\u00ed, calculamos media por cada semilla:"]}, {"cell_type": "code", "execution_count": 49, "metadata": {"collapsed": true}, "outputs": [], "source": ["# Respuesta\n", "\n", "import numpy as np\n", "\n", "dictionary_importances = {}\n", "\n", "for feature in features_all_seeds:\n", "    dictionary_importances[feature] = []\n", "    for values in features_random_seed:\n", "        for element in values:\n", "            if element[0] == feature:\n", "                dictionary_importances[feature].append(element[1])\n", "                break\n", "    dictionary_importances[feature] = np.mean(dictionary_importances[feature])"]}, {"cell_type": "code", "execution_count": 50, "metadata": {"collapsed": false}, "outputs": [{"data": {"text/plain": ["[('APGAR_5_RECODE', 0.18264939681654854),\n", " ('APGAR_5', 0.1803826606406311),\n", " ('OBSTETRIC_GESTATION_WEEKS', 0.17302570129366404),\n", " ('APGAR_10', 0.1307703119045178),\n", " ('INFANT_WEIGHT_GRAMS', 0.1030116177462312),\n", " ('INFANT_BREASTFED_indexed', 0.0767927600327975)]"]}, "execution_count": 50, "metadata": {}, "output_type": "execute_result"}], "source": ["# Respuesta\n", "\n", "sorted(dictionary_importances.items(), key=lambda value: value[1], reverse=True)"]}], "metadata": {"kernelspec": {"display_name": "PySpark 2.4 (python 3.7)", "language": "python", "name": "pyspark2.4"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.2"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}
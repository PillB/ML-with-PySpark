{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\pablo\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: py4j==0.10.7 in c:\\users\\pablo\\anaconda3\\lib\\site-packages (from pyspark) (0.10.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import time\n",
    "import pyspark\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "            .config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:0.18.1\") \\\n",
    "            .getOrCreate()\n",
    "import mmlspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar un file .csv\n",
    "file_name = \"Data/train.csv\"\n",
    "\n",
    "titanic = spark.read.csv(file_name, sep=',', header=True, inferSchema=True)\n",
    "train, test = titanic.randomSplit([0.85, 0.15], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column 'PassengerId' does not have null values\n",
      "The column 'Survived' does not have null values\n",
      "The column 'Pclass' does not have null values\n",
      "The column 'Name' does not have null values\n",
      "The column 'Sex' does not have null values\n",
      "\tBe careful: there are null values in the column 'Age'\n",
      "The column 'SibSp' does not have null values\n",
      "The column 'Parch' does not have null values\n",
      "The column 'Ticket' does not have null values\n",
      "The column 'Fare' does not have null values\n",
      "\tBe careful: there are null values in the column 'Cabin'\n",
      "\tBe careful: there are null values in the column 'Embarked'\n"
     ]
    }
   ],
   "source": [
    "# Validar valores omitidos\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "for column in train.columns:\n",
    "    if train.where(F.col(column).isNull()).count() != 0:\n",
    "        print(\"\\tBe careful: there are null values in the column '{}'\".format(column))\n",
    "    else:\n",
    "        print(\"The column '{}' does not have null values\".format(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, IndexToString\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# tipos de variables\n",
    "train = train.select(col(\"Survived\"),col(\"Sex\"),col(\"Embarked\"),col(\"Pclass\").cast(\"float\"),\n",
    "                     col(\"Age\").cast(\"float\"),col(\"SibSp\").cast(\"float\"),col(\"Fare\").cast(\"float\"))\n",
    "test = test.select(col(\"Survived\"),col(\"Sex\"),col(\"Embarked\"),col(\"Pclass\").cast(\"float\"),\n",
    "                   col(\"Age\").cast(\"float\"),col(\"SibSp\").cast(\"float\"),col(\"Fare\").cast(\"float\"))\n",
    "\n",
    "# quitamos valores nulos no imputados\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "\n",
    "# Indexar labels\n",
    "train = StringIndexer(inputCol=\"Sex\", outputCol=\"indexedSex\").fit(train).transform(train)\n",
    "train = StringIndexer(inputCol=\"Embarked\", outputCol=\"indexedEmbarked\").fit(train).transform(train)\n",
    "train = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedSurvived\").fit(train).transform(train)\n",
    "test = StringIndexer(inputCol=\"Sex\", outputCol=\"indexedSex\").fit(test).transform(test)\n",
    "test = StringIndexer(inputCol=\"Embarked\", outputCol=\"indexedEmbarked\").fit(test).transform(test)\n",
    "test = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedSurvived\").fit(test).transform(test)\n",
    "# One Hot Encoder en los features indexados\n",
    "train = OneHotEncoder(inputCol=\"indexedSex\", outputCol=\"sexVec\").transform(train)\n",
    "train = OneHotEncoder(inputCol=\"indexedEmbarked\", outputCol=\"embarkedVec\").transform(train)\n",
    "test = OneHotEncoder(inputCol=\"indexedSex\", outputCol=\"sexVec\").transform(test)\n",
    "test = OneHotEncoder(inputCol=\"indexedEmbarked\", outputCol=\"embarkedVec\").transform(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos vector assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Feature assembler as a vector\n",
    "train = train.withColumnRenamed('Survived', 'label')\n",
    "train = VectorAssembler(inputCols=[\"Pclass\",\"sexVec\",\"embarkedVec\", \"Age\",\"SibSp\",\"Fare\"],\n",
    "                        outputCol=\"features\").transform(train)\n",
    "test = test.withColumnRenamed('Survived', 'label')\n",
    "test = VectorAssembler(inputCols=[\"Pclass\",\"sexVec\",\"embarkedVec\", \"Age\",\"SibSp\",\"Fare\"],\n",
    "                       outputCol=\"features\").transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmlspark.lightgbm import LightGBMClassifier\n",
    "from mmlspark.train import TrainClassifier\n",
    "model = LightGBMClassifier(learningRate=0.3,\n",
    "                           numIterations=100,\n",
    "                           numLeaves=31).fit(train)\n",
    "\n",
    "scoredData = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>DenseMatrix([[64.,  8.],\\n             [12., 3...</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.887897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation_type                                   confusion_matrix  \\\n",
       "0  Classification  DenseMatrix([[64.,  8.],\\n             [12., 3...   \n",
       "\n",
       "   accuracy  precision    recall       AUC  \n",
       "0  0.824561   0.789474  0.714286  0.887897  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluacion del modelo\n",
    "from mmlspark.train import ComputeModelStatistics\n",
    "metrics = ComputeModelStatistics(evaluationMetric='classification',\n",
    "                                 labelCol='label',\n",
    "                                 scoresCol='rawPrediction',\n",
    "                                 scoredLabelsCol='prediction').transform(scoredData)\n",
    "metrics.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>DenseMatrix([[349.,   3.],\\n             [  9....</td>\n",
       "      <td>0.979933</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.99877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation_type                                   confusion_matrix  \\\n",
       "0  Classification  DenseMatrix([[349.,   3.],\\n             [  9....   \n",
       "\n",
       "   accuracy  precision    recall      AUC  \n",
       "0  0.979933     0.9875  0.963415  0.99877  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = model.transform(train)\n",
    "metrics = ComputeModelStatistics(evaluationMetric='classification',\n",
    "                                 labelCol='label',\n",
    "                                 scoresCol='rawPrediction',\n",
    "                                 scoredLabelsCol='prediction').transform(trainData)\n",
    "metrics.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
